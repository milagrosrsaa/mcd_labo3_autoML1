{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "  <h2>Trabajo Laboratorio de Implementación III - MCD Virtual Cohorte 2022</h2>\n",
    "  <h3>Forecasting para una Empresa de Consumo Masivo</h3>\n",
    "  <h4>Creación de dataset group</h4>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerias\n",
    "\n",
    "# !pip install awswrangler\n",
    "# !pip install boto3\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha inicio historia 2017-01-01 00:00:00\n",
      "Fecha fin historia 2019-12-01 00:00:00\n",
      "Fecha futura (related time series) 2020-02-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Definición fechas\n",
    "\n",
    "date_start=datetime.strptime('2017-01-01', '%Y-%m-%d')\n",
    "date_end=datetime.strptime('2019-12-01', '%Y-%m-%d')\n",
    "forecast_length = 2\n",
    "date_future=date_end+relativedelta(months=forecast_length)\n",
    "years=range(2018, 2020)\n",
    "\n",
    "print(f\"Fecha inicio historia {date_start}\")\n",
    "print(f\"Fecha fin historia {date_end}\")\n",
    "print(f\"Fecha futura (related time series) {date_future}\")\n",
    "\n",
    "timestamp_format=\"yyyy-MM-dd\"\n",
    "\n",
    "# Versión modelo\n",
    "data_version = '1'\n",
    "grouped_cols = \"product_id\"\n",
    "grouped_cols_name = \"product\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conexiones AWS\n",
    "\n",
    "account_id=boto3.client('sts').get_caller_identity().get('Account')\n",
    "session = boto3.Session() \n",
    "forecast = session.client(service_name='forecast')\n",
    "region = forecast.meta.region_name\n",
    "forecastquery = session.client(service_name='forecastquery')\n",
    "role = f'arn:aws:iam::{account_id}:role/ForecastRole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buckets de datos\n",
    "\n",
    "target_s3_path=f's3://datasets-forecast/modelo-{data_version}-forecast-{grouped_cols_name}/target/df_ventas_{grouped_cols_name}.csv'\n",
    "items_s3_path=f's3://datasets-forecast/modelo-{data_version}-forecast-{grouped_cols_name}/product/df_products.csv'\n",
    "related_s3_path=f's3://datasets-forecast/modelo-{data_version}-forecast-{grouped_cols_name}/related/df_related_{grouped_cols_name}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar comunicación con Amazon Forecast\n",
    "assert forecast.list_predictors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de datasets\n",
    "ts_dataset_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_target\"\n",
    "item_dataset_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_items\"\n",
    "related_dataset_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_related\"\n",
    "\n",
    "# Nombre de dataset group\n",
    "dataset_group_name = f'modelo_{data_version}_{grouped_cols_name}'\n",
    "\n",
    "# Nombre de import jobs\n",
    "target_import_job_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_target_import\"\n",
    "items_import_job_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_items_import\"\n",
    "related_import_job_name = f\"modelo_{data_version}_{grouped_cols_name}_dataset_related_import\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='datasets' />\n",
    "\n",
    "## Crear datasets en Amazon Forecast\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros\n",
    "\n",
    "Los datos deben ser importados sin header, por lo cual se debe definir un esquema. El orden de los atributos debe ser el mismo que el de las columnas de los archivos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Time Series Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_frequency='M'\n",
    "ts_schema = {\n",
    "\t\"Attributes\": [\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"timestamp\",\n",
    "\t\t\t\"AttributeType\": \"timestamp\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"item_id\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"target_value\",\n",
    "\t\t\t\"AttributeType\": \"float\"\n",
    "\t\t}\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente codigo funciona para crear dataset target según schema brindado. La siguiente salida arroja error porque este primer modelo fue ejecutado integramente desde la UI de forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceAlreadyExistsException",
     "evalue": "An error occurred (ResourceAlreadyExistsException) when calling the CreateDataset operation: A dataset already exists with the arn: arn:aws:forecast:us-east-1:637423651905:dataset/modelo_1_product_dataset_target",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceAlreadyExistsException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m create_dataset_response \u001b[38;5;241m=\u001b[39m \u001b[43mforecast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDomain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCUSTOM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mDatasetType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET_TIME_SERIES\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mDatasetName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mDataFrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mSchema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mts_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botocore\\client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\botocore\\client.py:1021\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1017\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mResourceAlreadyExistsException\u001b[0m: An error occurred (ResourceAlreadyExistsException) when calling the CreateDataset operation: A dataset already exists with the arn: arn:aws:forecast:us-east-1:637423651905:dataset/modelo_1_product_dataset_target"
     ]
    }
   ],
   "source": [
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='TARGET_TIME_SERIES',\n",
    "                                                  DatasetName=ts_dataset_name,\n",
    "                                                  DataFrequency=ts_frequency,\n",
    "                                                  Schema=ts_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset_arn=create_dataset_response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset_description=forecast.describe_dataset(DatasetArn=target_dataset_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Dataset with ARN {target_dataset_arn} is now {target_dataset_description['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items dataset schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_schema = {\n",
    "\t\"Attributes\": [\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"item_id\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"cat1\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"cat2\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"cat3\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"brand\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"sku_size\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t}\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='ITEM_METADATA',\n",
    "                                                  DatasetName=item_dataset_name,\n",
    "                                                  Schema=items_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dataset_arn=create_dataset_response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dataset_description=forecast.describe_dataset(DatasetArn=items_dataset_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Dataset with ARN {items_dataset_arn} is now {items_dataset_description['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related dataset schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_dataset_frequency='M'\n",
    "related_schema = {\n",
    "\t\"Attributes\": [\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"timestamp\",\n",
    "\t\t\t\"AttributeType\": \"timestamp\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"item_id\",\n",
    "\t\t\t\"AttributeType\": \"string\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"month_number\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"quarter\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"days_in_month\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"sundays\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"saturdays\",\n",
    "\t\t\t\"AttributeType\": \"integer\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"tn_m3\",\n",
    "\t\t\t\"AttributeType\": \"float\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"tn_m6\",\n",
    "\t\t\t\"AttributeType\": \"float\"\n",
    "\t\t},\n",
    "\t\t{\n",
    "\t\t\t\"AttributeName\": \"tn_m12\",\n",
    "\t\t\t\"AttributeType\": \"float\"\n",
    "\t\t}\n",
    "\t]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_response = forecast.create_dataset(Domain=\"CUSTOM\",\n",
    "                                                  DatasetType='RELATED_TIME_SERIES',\n",
    "                                                  DatasetName=related_dataset_name,\n",
    "                                                  DataFrequency=related_dataset_frequency,\n",
    "                                                  Schema=related_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_dataset_arn=create_dataset_response['DatasetArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_dataset_description=forecast.describe_dataset(DatasetArn=related_dataset_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The Dataset with ARN {related_dataset_arn} is now {related_dataset_description['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entrenar un predictor, requerimos un `DatasetGroup` que agrupa los datasets de input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_arns = [target_dataset_arn, items_dataset_arn, related_dataset_arn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = \\\n",
    "    forecast.create_dataset_group(Domain=\"CUSTOM\",\n",
    "                                  DatasetGroupName=dataset_group_name,\n",
    "                                  DatasetArns=dataset_arns)\n",
    "dataset_group_arn = create_dataset_group_response['DatasetGroupArn']\n",
    "describe_dataset_group_response = forecast.describe_dataset_group(DatasetGroupArn=dataset_group_arn)\n",
    "print(f\"The DatasetGroup with ARN {dataset_group_arn} is now {describe_dataset_group_response['Status']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='import' />\n",
    "\n",
    "## Importar datasets en Amazon Forecast\n",
    "[(back to top)](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target time series import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=target_import_job_name,\n",
    "                                       DatasetArn=target_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": target_s3_path,\n",
    "                                             \"RoleArn\": role\n",
    "                                         } \n",
    "                                       },\n",
    "                                       TimestampFormat=timestamp_format)\n",
    "\n",
    "target_dataset_import_job_arn = target_dataset_import_job_response['DatasetImportJobArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=target_dataset_import_job_arn)['Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items dataset import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=items_import_job_name,\n",
    "                                       DatasetArn=items_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": items_s3_path,\n",
    "                                             \"RoleArn\": role\n",
    "                                         } \n",
    "                                       })\n",
    "\n",
    "items_dataset_import_job_arn = items_dataset_import_job_response['DatasetImportJobArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=items_dataset_import_job_arn)['Status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Related dataset import job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "related_dataset_import_job_response = \\\n",
    "    forecast.create_dataset_import_job(DatasetImportJobName=related_import_job_name,\n",
    "                                       DatasetArn=related_dataset_arn,\n",
    "                                       DataSource= {\n",
    "                                         \"S3Config\" : {\n",
    "                                             \"Path\": related_s3_path,\n",
    "                                             \"RoleArn\": role\n",
    "                                         } \n",
    "                                       },\n",
    "                                       TimestampFormat=timestamp_format)\n",
    "\n",
    "related_dataset_import_job_arn = related_dataset_import_job_response['DatasetImportJobArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=related_dataset_import_job_arn)['Status']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
